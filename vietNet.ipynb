{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a212eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from SNNComponents import SpikingNeuronLayerRNN\n",
    "from SNNComponents import OutputDataToSpikingPerceptronLayer\n",
    "from SNNComponents import InputDataToSpikingPerceptronLayer\n",
    "\n",
    "from util import test, train, train_many_epochs, train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e048fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import load_train_test_sets\n",
    "\n",
    "batch_size = 1000\n",
    "training_set, testing_set = load_train_test_sets()\n",
    "train_set_loader = torch.utils.data.DataLoader(\n",
    "    dataset = training_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "test_set_loader = torch.utils.data.DataLoader(\n",
    "    dataset=testing_set,\n",
    "    batch_size=1,\n",
    "    shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99bd4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 64 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 8, 8\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_set), size=(1,)).item()\n",
    "    img, label = training_set[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "85bb4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VietNetSNN(nn.Module):\n",
    "    def __init__(self, device, n_time_steps, begin_eval):\n",
    "        super(VietNetSNN, self).__init__()\n",
    "        assert(0 <= begin_eval and begin_eval < n_time_steps)\n",
    "        self.device = device\n",
    "        self.n_time_steps = n_time_steps\n",
    "        self.begin_eval = begin_eval\n",
    "        \n",
    "        self.input_conversion = InputDataToSpikingPerceptronLayer(device)\n",
    "        \n",
    "        self.layer1 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=12*14, n_hidden=256, decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.5)\n",
    "        self.layer2 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=256, n_hidden=128, decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.25)\n",
    "        self.layer3 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=128, n_hidden=2, decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.5)\n",
    "        \n",
    "        self.all_layers = [self.layer1, self.layer2, self.layer3]\n",
    "        \n",
    "        self.output_conversion = OutputDataToSpikingPerceptronLayer(average_output=False)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward_through_time(self, x):\n",
    "        self.input_conversion.reset_state()\n",
    "        for layer in self.all_layers:\n",
    "            layer.reset_state()\n",
    "        out = []\n",
    "        all_states = []\n",
    "        all_outputs = []\n",
    "        \n",
    "        for _ in range(self.n_time_steps):\n",
    "            xi = self.input_conversion(x)\n",
    "            prev_layer_state, prev_layer_output = None, xi\n",
    "            for layer in self.all_layers:\n",
    "                layer_state, layer_output = layer(prev_layer_output)\n",
    "                prev_layer_state, prev_layer_output = layer_state, layer_output\n",
    "\n",
    "                all_states.append(layer_state)\n",
    "                all_outputs.append(layer_output)\n",
    "\n",
    "            out.append(prev_layer_state)\n",
    "        out = self.output_conversion(out[self.begin_eval:])\n",
    "        return out, [[layer_states, layer_outputs] \n",
    "                     for layer_states, layer_outputs in zip(all_states, all_outputs)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.forward_through_time(x)\n",
    "        return F.log_softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ba3edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VietNetSNN(nn.Module):\n",
    "    def __init__(self, device, n_time_steps, begin_eval):\n",
    "        super(VietNetSNN, self).__init__()\n",
    "        assert( 0 <= begin_eval and begin_eval < n_time_steps)\n",
    "        self.deice = device\n",
    "        self.n_time_steps = n_time_steps\n",
    "        self.begin_eval = begin_eval\n",
    "\n",
    "        self.input_conversion = InputDataToSpikingPerceptronLayer(device)\n",
    "\n",
    "        self.layer1 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=12*14, n_hidden=100, decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.5)\n",
    "\n",
    "        self.layer2 = SpikingNeuronLayerRNN(\n",
    "            device, n_inputs=100, n_hidden=2, decay_multiplier=0.9, threshold=1.0, penalty_threshold=1.5)\n",
    "\n",
    "        self.all_layers = [self.layer1, self.layer2]\n",
    "\n",
    "        self.output_conversion = OutputDataToSpikingPerceptronLayer(average_output=False)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward_through_time(self, x):\n",
    "        self.input_conversion.reset_state()\n",
    "        for layer in self.all_layers:\n",
    "            layer.reset_state()\n",
    "\n",
    "        out = []\n",
    "        \n",
    "        all_states = []\n",
    "        all_outputs = []\n",
    "\n",
    "        for _ in range(self.n_time_steps):\n",
    "            xi = self.input_conversion(x)\n",
    "            prev_layer_state, prev_layer_output = None, xi\n",
    "            for layer in self.all_layers:\n",
    "                layer_state, layer_output = layer(prev_layer_output)\n",
    "                prev_layer_state, prev_layer_output = layer_state, layer_output\n",
    "\n",
    "                all_states.append(layer_state)\n",
    "                all_outputs.append(layer_output)\n",
    "\n",
    "            out.append(prev_layer_state)\n",
    "        out = self.output_conversion(out[self.begin_eval:])\n",
    "        return out, [[layer_states, layer_outputs] \n",
    "                     for layer_states, layer_outputs in zip(all_states, all_outputs)]\n",
    "\n",
    "    def _DEP_forward_through_time(self, x):\n",
    "        self.input_conversion.reset_state()\n",
    "        self.layer1.reset_state()\n",
    "        self.layer2.reset_state()\n",
    "\n",
    "        out = []\n",
    "\n",
    "        all_layer1_states = []\n",
    "        all_layer1_outputs = []\n",
    "\n",
    "        all_layer2_states = []\n",
    "        all_layer2_outputs = []\n",
    "\n",
    "        for _ in range(self.n_time_steps):\n",
    "            xi = self.input_conversion(x)\n",
    "\n",
    "            layer1_state, layer1_output = self.layer1(xi)\n",
    "            layer2_state, layer2_output = self.layer2(layer1_output)\n",
    "\n",
    "            all_layer1_states.append(layer1_state)\n",
    "            all_layer1_outputs.append(layer1_output)\n",
    "\n",
    "            all_layer2_states.append(layer2_state)\n",
    "            all_layer2_outputs.append(layer2_output)\n",
    "            out.append(layer2_state)\n",
    "\n",
    "        out = self.output_conversion(out[self.begin_eval:])\n",
    "        return out, [[all_layer1_states, all_layer1_outputs],\n",
    "                     [all_layer2_states, all_layer2_outputs]]\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.forward_through_time(x)\n",
    "        return F.log_softmax(out, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a0e18bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VietNetCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VietNetCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,\n",
    "                     out_channels=16,\n",
    "                     kernel_size=5,\n",
    "                     stride=1,\n",
    "                     padding=2,\n",
    "                ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(288, 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        out = self.sigmoid(self.out(x))\n",
    "        return out, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6b629b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCELoss()\n",
    "cnn = VietNetCNN()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6474128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "num_epochs = 20\n",
    "\n",
    "def train(num_epochs, cnn, train_loader, test_loader):\n",
    "    cnn.train()\n",
    "    \n",
    "    total_steps = len(train_loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            b_x = Variable(images)\n",
    "            b_y = Variable(labels)\n",
    "            \n",
    "            raw_out = cnn(b_x)\n",
    "            output = raw_out[0].reshape(b_y.shape)\n",
    "\n",
    "            b_y = b_y.float()\n",
    "            loss = loss_func(output, b_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], loss: {loss.item():.4f}')\n",
    "            if (i+1) % 100 == 0: \n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], loss: {loss.item():.4f}')\n",
    "                \n",
    "def test(test_loader):\n",
    "    cnn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for image, labels in test_loader:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.round(test_output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2e88fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_set_loader, optimizer, epoch, logging_interval=100):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_set_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        #print(output)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % logging_interval == 0:\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct = pred.eq(target.view_as(pred)).float().mean().item()\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f} Accuracy: {:.2f}%'.format(\n",
    "                epoch, batch_idx * len(data), len(train_set_loader.dataset),\n",
    "                100. * batch_idx / len(train_set_loader), loss.item(),\n",
    "                100. * correct))\n",
    "            \n",
    "\n",
    "def test(model, device, test_set_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_set_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            print(output)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduce=True).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            print(pred)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_set_loader.dataset)\n",
    "    print()\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss,\n",
    "        correct, len(test_set_loader.dataset),\n",
    "        100. * correct / len(test_set_loader.dataset)))\n",
    "    print(\"\")\n",
    "    \n",
    "def train_epochs(model, device, train_set_loader, test_set_loader, epochs, lr=0.1, lr_decay=0.5, momentum=0.5):\n",
    "    for e in range(1, epochs+1):\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr* (e * lr_decay), momentum=momentum)\n",
    "        train(model, device, train_set_loader, optimizer, e, logging_interval=10)\n",
    "        test(model, device, test_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1127f1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/49417 (0%)] Loss: 818483.312500 Accuracy: 50.50%\n",
      "Train Epoch: 1 [10000/49417 (20%)] Loss: nan Accuracy: 55.00%\n",
      "Train Epoch: 1 [20000/49417 (40%)] Loss: nan Accuracy: 54.40%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10054/3974946969.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mspiking_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVietNetSNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_time_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspiking_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10054/2479665256.py\u001b[0m in \u001b[0;36mtrain_epochs\u001b[0;34m(model, device, train_set_loader, test_set_loader, epochs, lr, lr_decay, momentum)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10054/2479665256.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_set_loader, optimizer, epoch, logging_interval)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spiking_model = VietNetSNN(device, n_time_steps = 128, begin_eval=0)\n",
    "train_epochs(spiking_model, device, train_set_loader, train_set_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53af35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03459d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
